{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b4f9f0",
   "metadata": {},
   "source": [
    "# Adaptive Learning Path Workflow with LangGraph\n",
    "\n",
    "This notebook rebuilds the adaptive learning path workflow using only LangGraph nodes and edges. Each workflow step is a node, and transitions are managed by the LangGraph graph API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd809bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Required Libraries\n",
    "from langgraph.graph import StateGraph\n",
    "import re\n",
    "import datetime\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file if present\n",
    "load_dotenv()\n",
    "\n",
    "# Gemini/OpenRouter config (set via environment variables)\n",
    "GEMINI_MODEL = os.environ.get('GEMINI_MODEL')\n",
    "GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY', None)\n",
    "\n",
    "print(f\"Using Gemini Model: {GEMINI_MODEL}\")\n",
    "print(f\"GEMINI_API_KEY set: {'yes' if GEMINI_API_KEY else 'no'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define Roadmap State Structure\n",
    "class RoadmapState:\n",
    "    def __init__(self):\n",
    "        self.topic = None\n",
    "        self.goal = None\n",
    "        self.learning_style = None\n",
    "        self.available_time = None\n",
    "        self.roadmap = None\n",
    "        self.feedback = None\n",
    "        self.revised_roadmap = None\n",
    "        self.estimated_level = None\n",
    "        self.prereqs_needed = None\n",
    "        self.primer = None\n",
    "        self.schedule = None\n",
    "        self.target_duration_weeks = None\n",
    "        self.resources = None\n",
    "        self.module_progress = {}\n",
    "        self.quiz_scores = []\n",
    "        self.timestamps = {}\n",
    "    def to_dict(self):\n",
    "        return self.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8eef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define Node Functions\n",
    "# Each function below is a workflow node\n",
    "# Helper to accept either dict or RoadmapState and return RoadmapState object\n",
    "def _ensure_state(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        s = RoadmapState()\n",
    "        s.__dict__.update(obj)\n",
    "        return s\n",
    "    return obj\n",
    "\n",
    "def node_topic_goal(state):\n",
    "    state = _ensure_state(state)\n",
    "    print(\"Welcome to the Roadmap/Learning Path Maker!\")\n",
    "    if not state.topic:\n",
    "        state.topic = input(\"Enter the topic you want to learn (e.g., Python for Data Science): \")\n",
    "    else:\n",
    "        print(f\"Using topic: {state.topic}\")\n",
    "    if not state.goal:\n",
    "        state.goal = input(\"Describe your learning goal (e.g., Get a job, Build a project, Pass a course): \")\n",
    "    else:\n",
    "        print(f\"Using goal: {state.goal}\")\n",
    "    import datetime\n",
    "    if not hasattr(state, 'timestamps') or state.timestamps is None:\n",
    "        state.timestamps = {}\n",
    "    state.timestamps['started'] = datetime.datetime.utcnow().isoformat() + 'Z'\n",
    "    return state.__dict__\n",
    "def call_gemini(prompt, model=None, api_key=None, max_tokens=512, timeout_seconds=60):\n",
    "    \"\"\"Call OpenRouter via the openai-python client (OpenAI class).\n",
    "    - Fails fast if no API key is configured (raises ValueError).\n",
    "    - Logs timing and errors to help debug why requests don't appear in OpenRouter logs.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    if model is None:\n",
    "        model = GEMINI_MODEL\n",
    "    # resolve API key from parameter or environment\n",
    "    if api_key is None:\n",
    "        api_key = os.environ.get('GEMINI_API_KEY')\n",
    "    if not api_key:\n",
    "        # Fail fast — do not prompt interactively in notebook runs\n",
    "        raise ValueError('GEMINI_API_KEY not set. Set env var GEMINI_API_KEY before running or pass api_key to call_gemini.')\n",
    "    # Minimal debug info (do NOT print the key itself)\n",
    "    print(f\"[LLM] calling model={model} (api_key set: yes) — prompt preview: {prompt[:120].replace('\\n',' ')}...\")\n",
    "    client = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=api_key)\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        # include only required args to reduce client-side shaping issues\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}],\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        duration = time.time() - t0\n",
    "        print(f\"[LLM] request completed in {duration:.2f}s\")\n",
    "    except Exception as e:\n",
    "        duration = time.time() - t0\n",
    "        print(f\"[LLM] request failed after {duration:.2f}s: {e}\")\n",
    "        # Surface the error so you see it in notebook output and can inspect OpenRouter logs\n",
    "        raise\n",
    "    # Normalize returned content\n",
    "    content = None\n",
    "    try:\n",
    "        content = completion.choices[0].message.content\n",
    "    except Exception:\n",
    "        try:\n",
    "            content = completion.choices[0].text\n",
    "        except Exception:\n",
    "            content = str(completion)\n",
    "    if isinstance(content, list):\n",
    "        parts = []\n",
    "        for part in content:\n",
    "            if isinstance(part, dict) and 'text' in part:\n",
    "                parts.append(part['text'])\n",
    "            elif isinstance(part, str):\n",
    "                parts.append(part)\n",
    "        return ''.join(parts)\n",
    "    return str(content)\n",
    "def fetch_level_descriptions_batch(topic, model=None, api_key=None):\n",
    "    \"\"\"Request a single JSON object from the LLM that maps CEFR levels to short descriptions.\n",
    "    Returns a dict: { 'None': '...', 'A1': '...', ... }\n",
    "    \"\"\"\n",
    "    import json, re\n",
    "    if model is None:\n",
    "        model = GEMINI_MODEL\n",
    "    prompt = (\n",
    "        f\"Return a JSON object mapping the following levels to a short phrase or one-sentence description for the topic '{topic}':\\\\n\"\n",
    "        \"Levels: None, A1, A2, B1, B2, C1, C2.\\\\n\"\n",
    "        \"Format EXACTLY as a JSON object with those keys and short values. Do not add commentary. Example response: {\\\"None\\\": \\\"No prior knowledge\\\", \\\"A1\\\": \\\"Familiar with basics\\\", ... }\\\\n\"\n",
    "        \"Keep each value concise (one short sentence or phrase).\"\n",
    "    )\n",
    "    resp = call_gemini(prompt, model=model, api_key=api_key, max_tokens=400)\n",
    "    print(\"[LLM] raw level-descriptions response preview:\", resp[:400])\n",
    "    # Try to parse JSON directly\n",
    "    try:\n",
    "        parsed = json.loads(resp)\n",
    "        if isinstance(parsed, dict):\n",
    "            return {k: str(v).strip() for k, v in parsed.items()}\n",
    "    except Exception:\n",
    "        # attempt to extract JSON substring\n",
    "        m = re.search(r\"(\\{[\\s\\S]*\\})\", resp)\n",
    "        if m:\n",
    "            try:\n",
    "                parsed = json.loads(m.group(1))\n",
    "                if isinstance(parsed, dict):\n",
    "                    return {k: str(v).strip() for k, v in parsed.items()}\n",
    "            except Exception:\n",
    "                pass\n",
    "    # If parsing failed, fallback to a safe default (call per-level)\n",
    "    print('[LLM] failed to parse JSON from batch response; falling back to individual calls')\n",
    "    levels = ['None', 'A1', 'A2', 'B1', 'B2', 'C1', 'C2']\n",
    "    descriptions = {}\n",
    "    for lvl in levels:\n",
    "        prompt = f\"For the topic '{topic}', in one short sentence or a few phrases describe what the '{lvl}' skill level means. Be practical and concise.\"\n",
    "        desc = call_gemini(prompt, model=model, api_key=api_key, max_tokens=160)\n",
    "        descriptions[lvl] = desc.strip() if desc else f\"({lvl} description unavailable)\"\n",
    "    return descriptions\n",
    "def get_topic_level_descriptions_cached(state):\n",
    "    state = _ensure_state(state)\n",
    "    \"\"\"Return cached level descriptions in state._level_desc_cache if present, otherwise fetch and cache them.\"\"\"\n",
    "    if hasattr(state, '_level_desc_cache') and getattr(state, '_level_desc_cache', {}).get('topic') == getattr(state, 'topic', None):\n",
    "        return state._level_desc_cache['descriptions']\n",
    "    descriptions = fetch_level_descriptions_batch(getattr(state, 'topic', 'the topic'))\n",
    "    state._level_desc_cache = {'topic': getattr(state, 'topic', None), 'descriptions': descriptions}\n",
    "    return descriptions\n",
    "def node_level_selection(state):\n",
    "    state = _ensure_state(state)\n",
    "    levels = ['None', 'A1', 'A2', 'B1', 'B2', 'C1', 'C2']\n",
    "    # Use cached/batched descriptions to avoid repeated requests\n",
    "    level_descriptions = get_topic_level_descriptions_cached(state)\n",
    "    print(f\"Select your current level for this topic: {getattr(state, 'topic', '')}\")\n",
    "    if not state.estimated_level:\n",
    "        for i, lvl in enumerate(levels):\n",
    "            print(f\"  {i}: {lvl} - {level_descriptions.get(lvl, '')}\")\n",
    "        idx = input(\"Enter the number for your level (0-6): \").strip()\n",
    "        try:\n",
    "            idx = int(idx)\n",
    "            if 0 <= idx < len(levels):\n",
    "                state.estimated_level = levels[idx]\n",
    "            else:\n",
    "                state.estimated_level = 'None'\n",
    "        except Exception:\n",
    "            state.estimated_level = 'None'\n",
    "    else:\n",
    "        print(f\"Using level: {state.estimated_level}\")\n",
    "    print(f\"Selected level: {state.estimated_level} - {level_descriptions.get(state.estimated_level, '')}\")\n",
    "    return state.__dict__\n",
    "def node_background(state):\n",
    "    state = _ensure_state(state)\n",
    "    if not state.learning_style:\n",
    "        state.learning_style = input(\"Preferred learning style (Videos, Reading, Projects, Interactive, Mixed): \").strip()\n",
    "    else:\n",
    "        print(f\"Using learning style: {state.learning_style}\")\n",
    "    if not state.available_time:\n",
    "        state.available_time = input(\"How much time per week? (e.g., 5 hours): \").strip() or '5 hours'\n",
    "    else:\n",
    "        print(f\"Using available time: {state.available_time}\")\n",
    "    if not state.target_duration_weeks:\n",
    "        weeks = input(\"How many weeks are you willing to commit to this plan? (e.g., 8): \").strip()\n",
    "        try:\n",
    "            state.target_duration_weeks = int(weeks)\n",
    "        except Exception:\n",
    "            state.target_duration_weeks = None\n",
    "    else:\n",
    "        print(f\"Using target duration: {state.target_duration_weeks} weeks\")\n",
    "    return state.__dict__\n",
    "def node_prerequisite_check(state):\n",
    "    state = _ensure_state(state)\n",
    "    prompt = f\"You are an expert instructor for the topic: {getattr(state, 'topic', None)}. List up to 6 concise prerequisite topics or skills a learner should know before starting {getattr(state, 'topic', None)}.\"\n",
    "    prereq_text = call_gemini(prompt)\n",
    "    print('\\n--- PREREQUISITES (LLM) ---\\n')\n",
    "    print(prereq_text)\n",
    "    state.prereqs_needed = prereq_text.split('\\n') if prereq_text else []\n",
    "    wants_primer = input(\"Would you like a short primer that covers these prerequisites? (yes/no): \").strip().lower()\n",
    "    if wants_primer in ('yes','y') and state.prereqs_needed :\n",
    "        primer_prompt = f\"Create a short primer for: {', '.join([p for p in state.prereqs_needed if p])}\"\n",
    "        state.primer = call_gemini(primer_prompt)\n",
    "        print(state.primer)\n",
    "    return state.__dict__\n",
    "def node_generate_roadmap(state):\n",
    "    state = _ensure_state(state)\n",
    "    roadmap_prompt = f\"\"\"Create a concise, actionable learning roadmap based on the following details:\n",
    "\n",
    "Topic: {getattr(state, 'topic', 'Unknown')}\n",
    "Goal: {getattr(state, 'goal', 'Unknown')}\n",
    "Level: {getattr(state, 'estimated_level', 'Unknown')}\n",
    "Learning Style: {getattr(state, 'learning_style', 'Unknown')}\n",
    "Time per Week: {getattr(state, 'available_time', 'Unknown')}\n",
    "Duration: {getattr(state, 'target_duration_weeks', 'Unknown')} weeks\n",
    "\n",
    "Provide a structured roadmap with modules, timelines, and resources. Do not use placeholders like [Undefined]; use the provided values directly.\"\"\"\n",
    "    state.roadmap = call_gemini(roadmap_prompt)\n",
    "    print(\"\\n--- ROADMAP ---\\n\")\n",
    "    print(state.roadmap)\n",
    "    return state.__dict__\n",
    "def node_review_feedback(state):\n",
    "    state = _ensure_state(state)\n",
    "    print(\"\\n--- USER REVIEW & FEEDBACK ---\\n\")\n",
    "    print(\"Here is your generated roadmap:\")\n",
    "    print(getattr(state, 'roadmap', ''))\n",
    "    if not state.feedback:\n",
    "        feedback = input(\"Do you want to request changes to the roadmap? If yes, describe them. If no, type 'no': \").strip()\n",
    "        state.feedback = feedback\n",
    "    else:\n",
    "        print(f\"Using feedback: {state.feedback}\")\n",
    "    return state.__dict__\n",
    "def node_adaptive_branch(state):\n",
    "    state = _ensure_state(state)\n",
    "    feedback = getattr(state, 'feedback', None)\n",
    "    if feedback and feedback.strip().lower() != 'no':\n",
    "        print(\"Adapting roadmap based on feedback...\")\n",
    "        # call roadmap generator which returns a dict; rehydrate into the object\n",
    "        new_dict = node_generate_roadmap(state)\n",
    "        new_state = RoadmapState()\n",
    "        new_state.__dict__.update(new_dict)\n",
    "        state = new_state\n",
    "    return state.__dict__\n",
    "def node_resource_fetch(state):\n",
    "    state = _ensure_state(state)\n",
    "    print(\"Fetching resources for modules...\")\n",
    "    state.resources = call_gemini(f\"Suggest resources for roadmap: {getattr(state, 'roadmap', '')}\")\n",
    "    return state.__dict__\n",
    "def node_schedule_builder(state):\n",
    "    state = _ensure_state(state)\n",
    "    print(\"Building schedule...\")\n",
    "    state.schedule = call_gemini(f\"Build a schedule for roadmap: {getattr(state, 'roadmap', '')}\")\n",
    "    return state.__dict__\n",
    "def node_final_output(state):\n",
    "    state = _ensure_state(state)\n",
    "    print(\"\\n--- FINAL OUTPUT ---\\n\")\n",
    "    print(f\"Roadmap: {getattr(state, 'roadmap', '')}\\nSchedule: {getattr(state, 'schedule', '')}\\nResources: {getattr(state, 'resources', '')}\")\n",
    "    return state.__dict__\n",
    "def node_module_quiz_branch(state):\n",
    "    state = _ensure_state(state)\n",
    "    print(\"Module quiz branch...\")\n",
    "    if not hasattr(state, 'quiz_scores') or state.quiz_scores is None:\n",
    "        state.quiz_scores = []\n",
    "    import datetime\n",
    "    state.quiz_scores.append({'module': 'Example', 'score': 3, 'timestamp': datetime.datetime.utcnow().isoformat() + 'Z'})\n",
    "    return state.__dict__\n",
    "def node_progress_tracking(state):\n",
    "    state = _ensure_state(state)\n",
    "    print(\"\\n--- PROGRESS TRACKING ---\\n\")\n",
    "    print(f\"Module progress: {getattr(state, 'module_progress', {})}\")\n",
    "    print(f\"Quiz scores: {getattr(state, 'quiz_scores', [])}\")\n",
    "    if not hasattr(state, 'export_schedule') or state.export_schedule is None:\n",
    "        try:\n",
    "            choice = input(\"Would you like to export the schedule to an .ics file? (yes/no): \").strip().lower()\n",
    "            state.export_schedule = True if choice in ('yes', 'y') else False\n",
    "        except Exception:\n",
    "            state.export_schedule = False\n",
    "    else:\n",
    "        print(f\"Using export choice: {'yes' if state.export_schedule else 'no'}\")\n",
    "    return state.__dict__\n",
    "def node_export_schedule_ics(state):\n",
    "    state = _ensure_state(state)\n",
    "    if not getattr(state, 'export_schedule', False):\n",
    "        print('Export skipped (user chose not to export).')\n",
    "        return state.__dict__\n",
    "    import datetime, uuid, os, json, re\n",
    "    def to_dt_iso(s):\n",
    "        try:\n",
    "            if isinstance(s, str) and s.endswith('Z'):\n",
    "                return datetime.datetime.fromisoformat(s.replace('Z','+00:00'))\n",
    "            return datetime.datetime.fromisoformat(s)\n",
    "        except Exception:\n",
    "            try:\n",
    "                return datetime.datetime.strptime(s, '%Y-%m-%d')\n",
    "            except Exception:\n",
    "                return None\n",
    "    events = []\n",
    "    if hasattr(state, 'schedule_items') and isinstance(state.schedule_items, list) and state.schedule_items :\n",
    "        events = state.schedule_items\n",
    "    else:\n",
    "        sch_text = getattr(state, 'schedule','')\n",
    "        if sch_text:\n",
    "            prompt = f\"\"\"Convert the following schedule text into a JSON array of events. Each event should have 'title', 'start' (ISO8601), and 'end' (ISO8601).\\nSchedule text:\\n{sch_text}\\nReturn ONLY valid JSON, example: [{{\"title\":\"Module 1\",\"start\":\"2025-11-20T10:00:00Z\",\"end\":\"2025-11-20T12:00:00Z\"}}]\"\"\"\n",
    "            resp = None\n",
    "            try:\n",
    "                resp = call_gemini(prompt, max_tokens=600)\n",
    "            except Exception as e:\n",
    "                print('LLM parse for schedule failed:', e)\n",
    "            if resp:\n",
    "                try:\n",
    "                    parsed = json.loads(resp)\n",
    "                    if isinstance(parsed, list):\n",
    "                        events = parsed\n",
    "                except Exception:\n",
    "                    m = re.search(r\"(\\[\\s*\\{[\\s\\S]*\\}\\s*\\])\", resp)\n",
    "                    if m:\n",
    "                        try:\n",
    "                            parsed = json.loads(m.group(1))\n",
    "                            if isinstance(parsed, list):\n",
    "                                events = parsed\n",
    "                        except Exception:\n",
    "                            pass\n",
    "    target_weeks = getattr(state, 'target_duration_weeks', 0) or 0\n",
    "    expanded_events = []\n",
    "    if events and target_weeks and isinstance(target_weeks, int) and target_weeks > 0:\n",
    "        for ev in events:\n",
    "            s_raw = ev.get('start')\n",
    "            e_raw = ev.get('end')\n",
    "            sd = to_dt_iso(s_raw) if s_raw else None\n",
    "            ed = to_dt_iso(e_raw) if e_raw else None\n",
    "            if not sd or not ed:\n",
    "                continue\n",
    "            for w in range(max(1, target_weeks)):\n",
    "                occ_s = sd + datetime.timedelta(weeks=w)\n",
    "                occ_e = ed + datetime.timedelta(weeks=w)\n",
    "                expanded_events.append({\n",
    "                    'title': ev.get('title','Study'),\n",
    "                    'start': occ_s.isoformat().replace('+00:00','Z'),\n",
    "                    'end': occ_e.isoformat().replace('+00:00','Z'),\n",
    "                    'description': getattr(state, 'roadmap','')[:1000]\n",
    "                })\n",
    "        events = expanded_events\n",
    "    if not events:\n",
    "        print('No structured events found; writing placeholder calendar entries for the roadmap.')\n",
    "        now = datetime.datetime.utcnow()\n",
    "        base_start = now.replace(hour=9, minute=0, second=0, microsecond=0)\n",
    "        weeks = target_weeks if isinstance(target_weeks, int) and target_weeks > 0 else 1\n",
    "        events = []\n",
    "        for w in range(weeks):\n",
    "            start = base_start + datetime.timedelta(weeks=w)\n",
    "            end = start + datetime.timedelta(hours=1)\n",
    "            events.append({'title': f\"Study: {getattr(state, 'topic','Roadmap')}\", 'start': start.isoformat()+'Z', 'end': end.isoformat()+'Z', 'description': getattr(state, 'roadmap','')[:1000]})\n",
    "    tz = 'UTC'\n",
    "    uid_base = uuid.uuid4().hex\n",
    "    ics_lines = [\n",
    "        'BEGIN:VCALENDAR',\n",
    "        'VERSION:2.0',\n",
    "        'PRODID:-//LangGraph Roadmap//EN',\n",
    "        f'NAME:Roadmap Schedule for {getattr(state, \"topic\",\"\")}',\n",
    "    ]\n",
    "    for i, ev in enumerate(events):\n",
    "        title = ev.get('title','Event')\n",
    "        s = ev.get('start')\n",
    "        e = ev.get('end')\n",
    "        desc = ev.get('description','')\n",
    "        sd = to_dt_iso(s) if s else None\n",
    "        ed = to_dt_iso(e) if e else None\n",
    "        if not sd or not ed:\n",
    "            continue\n",
    "        def fmt(dt):\n",
    "            return dt.astimezone(datetime.timezone.utc).strftime('%Y%m%dT%H%M%SZ')\n",
    "        ics_lines += [\n",
    "            'BEGIN:VEVENT',\n",
    "            f'UID:{uid_base}-{i}@langgraph.local',\n",
    "            f'DTSTAMP:{fmt(datetime.datetime.utcnow())}',\n",
    "            f'DTSTART:{fmt(sd)}',\n",
    "            f'DTEND:{fmt(ed)}',\n",
    "            f'SUMMARY:{title}',\n",
    "        ]\n",
    "        if desc:\n",
    "            ics_lines.append(f'DESCRIPTION:{desc.replace('\\n','\\\\n')}')\n",
    "        ics_lines.append('END:VEVENT')\n",
    "    ics_lines.append('END:VCALENDAR')\n",
    "    ics_content = '\\n'.join(ics_lines)\n",
    "    out_name = f\"schedule-{datetime.datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.ics\"\n",
    "    out_path = os.path.join(os.getcwd(), out_name)\n",
    "    try:\n",
    "        with open(out_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(ics_content)\n",
    "        state.ics_file = out_path\n",
    "        print(f\"Schedule exported to {out_path}\")\n",
    "    except Exception as e:\n",
    "        print('Failed to write .ics file:', e)\n",
    "    return state.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac25751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 Quick OpenRouter connectivity test\n",
    "def test_openrouter_once():\n",
    "    \"\"\"Quick test to verify requests reach OpenRouter and measure latency.\n",
    "    Ensure `GEMINI_API_KEY` is set in environment before running.\n",
    "    \"\"\"\n",
    "    import time, os\n",
    "    api_key = os.environ.get('GEMINI_API_KEY')\n",
    "    if not api_key:\n",
    "        print('GEMINI_API_KEY not found in environment. Set it and re-run this cell.')\n",
    "        return\n",
    "    client = OpenAI(base_url='https://openrouter.ai/api/v1', api_key=api_key)\n",
    "    prompt = 'Hello — send a one-word response: Hi'\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        c = client.chat.completions.create(\n",
    "            model=GEMINI_MODEL,\n",
    "            messages=[{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":prompt}]}],\n",
    "            max_tokens=8,\n",
    "        )\n",
    "        dt = time.time() - t0\n",
    "        try:\n",
    "            content = c.choices[0].message.content\n",
    "        except Exception:\n",
    "            content = getattr(c.choices[0], 'text', str(c))\n",
    "        print(f'OpenRouter test OK — took {dt:.2f}s')\n",
    "        print('Response preview:', content if isinstance(content, str) else str(content)[:200])\n",
    "    except Exception as e:\n",
    "        print('OpenRouter test failed:', e)\n",
    "        raise\n",
    "\n",
    "# To run the quick test, call `test_openrouter_once()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create LangGraph Nodes\n",
    "nodes = {\n",
    "    'topic_goal': node_topic_goal,\n",
    "    'level_selection': node_level_selection,\n",
    "    'background': node_background,\n",
    "    'prerequisite_check': node_prerequisite_check,\n",
    "    'roadmap_generation': node_generate_roadmap,\n",
    "    'review_feedback': node_review_feedback,\n",
    "    'adaptive_branch': node_adaptive_branch,\n",
    "    'resource_fetch': node_resource_fetch,\n",
    "    'schedule_builder': node_schedule_builder,\n",
    "    'final_output': node_final_output,\n",
    "    'export_ics': node_export_schedule_ics,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b884d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define Workflow Edges\n",
    "edges = [\n",
    "    ('topic_goal', 'level_selection'),\n",
    "    ('level_selection', 'background'),\n",
    "    ('background', 'prerequisite_check'),\n",
    "    ('prerequisite_check', 'roadmap_generation'),\n",
    "    ('roadmap_generation', 'review_feedback'),\n",
    "    # feedback handled in adaptive_branch\n",
    "    ('review_feedback', 'adaptive_branch'),\n",
    "    ('adaptive_branch', 'resource_fetch'),\n",
    "    ('resource_fetch', 'schedule_builder'),\n",
    "    ('schedule_builder', 'final_output'),\n",
    "    # directly connect final output to export (export node remains optional)\n",
    "    ('final_output', 'export_ics'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d131300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Build and Visualize the LangGraph Workflow\n",
    "sg = StateGraph(RoadmapState)\n",
    "for name, func in nodes.items():\n",
    "    sg.add_node(name, func)\n",
    "for src, dst in edges:\n",
    "    sg.add_edge(src, dst)\n",
    "sg.set_entry_point('topic_goal')\n",
    "\n",
    "# Compile the StateGraph to a runnable graph object\n",
    "graph = sg.compile()\n",
    "\n",
    "# Try to render a mermaid PNG using LangGraph's graph renderer if available, otherwise fallback to networkx plot\n",
    "from IPython.display import Image, display\n",
    "try:\n",
    "    g = graph.get_graph()\n",
    "    try:\n",
    "        png_bytes = g.draw_mermaid_png()\n",
    "        display(Image(png_bytes))\n",
    "    except Exception as e:\n",
    "        print('Mermaid PNG render not available or failed:', e)\n",
    "        # fallback to networkx drawing\n",
    "        import networkx as _nx\n",
    "        import matplotlib.pyplot as _plt\n",
    "        nxg = _nx.DiGraph()\n",
    "        for s,d in edges:\n",
    "            nxg.add_edge(s,d)\n",
    "        _plt.figure(figsize=(12,6))\n",
    "        pos = _nx.spring_layout(nxg, seed=42)\n",
    "        _nx.draw(nxg, pos, with_labels=True, node_color='lightblue', node_size=2000, font_size=10, arrows=True)\n",
    "        _plt.title('LangGraph Workflow Structure (fallback)')\n",
    "        _plt.show()\n",
    "except Exception as e:\n",
    "    print('Graph object not renderable:', e)\n",
    "    # final fallback: networkx as above\n",
    "    import networkx as _nx\n",
    "    import matplotlib.pyplot as _plt\n",
    "    nxg = _nx.DiGraph()\n",
    "    for s,d in edges:\n",
    "        nxg.add_edge(s,d)\n",
    "    _plt.figure(figsize=(12,6))\n",
    "    pos = _nx.spring_layout(nxg, seed=42)\n",
    "    _nx.draw(nxg, pos, with_labels=True, node_color='lightblue', node_size=2000, font_size=10, arrows=True)\n",
    "    _plt.title('LangGraph Workflow Structure (fallback)')\n",
    "    _plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e76d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 7. Run the LangGraph Workflow\n",
    "# graph = sg.compile()\n",
    "# state = {}\n",
    "# state['topic'] = input(\"Enter the topic you want to learn (e.g., Python for Data Science): \")\n",
    "# state['goal'] = input(\"Describe your learning goal (e.g., Get a job, Build a project, Pass a course): \")\n",
    "# levels = ['None', 'A1', 'A2', 'B1', 'B2', 'C1', 'C2']\n",
    "# print(\"Select your current level:\")\n",
    "# for i, lvl in enumerate(levels):\n",
    "#     print(f\"  {i}: {lvl}\")\n",
    "# idx = input(\"Enter the number for your level (0-6): \").strip()\n",
    "# try:\n",
    "#     idx = int(idx)\n",
    "#     state['estimated_level'] = levels[idx] if 0 <= idx < len(levels) else 'None'\n",
    "# except:\n",
    "#     state['estimated_level'] = 'None'\n",
    "# state['learning_style'] = input(\"Preferred learning style (Videos, Reading, Projects, Interactive, Mixed): \").strip()\n",
    "# state['available_time'] = input(\"How much time per week? (e.g., 5 hours): \").strip() or '5 hours'\n",
    "# weeks = input(\"How many weeks are you willing to commit to this plan? (e.g., 8): \").strip()\n",
    "# try:\n",
    "#     state['target_duration_weeks'] = int(weeks)\n",
    "# except:\n",
    "#     state['target_duration_weeks'] = None\n",
    "# choice = input(\"Would you like to export the schedule to an .ics file? (yes/no): \").strip().lower()\n",
    "# state['export_schedule'] = True if choice in ('yes', 'y') else False\n",
    "# # LangGraph expects dict updates — pass a dict as initial input\n",
    "# output = graph.invoke(state)\n",
    "# print(\"\\n--- Workflow Complete ---\\n\")\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab53e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Interactive Notebook UI (single cell)\n",
    "# Lightweight UI using ipywidgets — fetches LLM-updated choices and runs the workflow in a background thread.\n",
    "import threading, sys\n",
    "from IPython.display import display, FileLink, HTML\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Widgets\n",
    "topic_w = widgets.Text(value='Python for DSA', description='Topic:', layout=widgets.Layout(width='70%'))\n",
    "goal_w = widgets.Text(value='Build a DSA project', description='Goal:', layout=widgets.Layout(width='70%'))\n",
    "level_w = widgets.Dropdown(options=['None','A1','A2','B1','B2','C1','C2'], description='Level:')\n",
    "style_w = widgets.Dropdown(options=['Videos','Reading','Projects','Interactive','Mixed'], description='Style:')\n",
    "time_w = widgets.Text(value='5 hours', description='Hours/week:')\n",
    "weeks_w = widgets.IntText(value=8, description='Weeks:')\n",
    "export_w = widgets.Checkbox(value=True, description='Export .ics')\n",
    "fetch_levels_btn = widgets.Button(description='Fetch Level Descriptions (LLM)', button_style='info')\n",
    "run_btn = widgets.Button(description='Run Workflow', button_style='primary')\n",
    "quick_btn = widgets.Button(description='Quick Roadmap → Schedule → Export', button_style='warning')\n",
    "test_btn = widgets.Button(description='Test OpenRouter', button_style='')\n",
    "\n",
    "out = widgets.Output(layout={'border': '1px solid black', 'height': '300px', 'overflow': 'auto'})\n",
    "\n",
    "# Helper writer to stream prints into the output widget\n",
    "class OutWriter:\n",
    "    def __init__(self, out_widget):\n",
    "        self.out = out_widget\n",
    "    def write(self, s):\n",
    "        try:\n",
    "            self.out.append_stdout(s)\n",
    "        except Exception:\n",
    "            pass\n",
    "    def flush(self):\n",
    "        pass\n",
    "\n",
    "# Fetch level descriptions via existing helper and update level_w options\n",
    "def fetch_levels_clicked(b):\n",
    "    fetch_levels_btn.disabled = True\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        print('Fetching level descriptions from LLM...')\n",
    "\n",
    "    def _work():\n",
    "        try:\n",
    "            # capture prints from LLM/node into the output widget\n",
    "            old_stdout = sys.stdout\n",
    "            sys.stdout = OutWriter(out)\n",
    "            try:\n",
    "                state = {'topic': topic_w.value}\n",
    "                descs = get_topic_level_descriptions_cached(state)\n",
    "                opts = [(f\"{k} - {v}\", k) for k, v in descs.items()]\n",
    "                level_w.options = opts\n",
    "                with out:\n",
    "                    print('Level descriptions updated.')\n",
    "            finally:\n",
    "                sys.stdout = old_stdout\n",
    "        except Exception as e:\n",
    "            with out:\n",
    "                print('Failed to fetch level descriptions:', e)\n",
    "        finally:\n",
    "            fetch_levels_btn.disabled = False\n",
    "\n",
    "    threading.Thread(target=_work, daemon=True).start()\n",
    "\n",
    "fetch_levels_btn.on_click(fetch_levels_clicked)\n",
    "\n",
    "# Run full workflow (keeps existing behaviour)\n",
    "def run_clicked(b):\n",
    "    run_btn.disabled = True\n",
    "    fetch_levels_btn.disabled = True\n",
    "    test_btn.disabled = True\n",
    "    quick_btn.disabled = True\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        print('Starting full workflow (may prompt for inputs in-node if present)...')\n",
    "\n",
    "    def _run():\n",
    "        state = {}\n",
    "        state['topic'] = topic_w.value\n",
    "        state['goal'] = goal_w.value\n",
    "        state['estimated_level'] = level_w.value\n",
    "        state['learning_style'] = style_w.value\n",
    "        state['available_time'] = time_w.value\n",
    "        state['target_duration_weeks'] = int(weeks_w.value) if weeks_w.value else None\n",
    "        state['export_schedule'] = bool(export_w.value)\n",
    "        try:\n",
    "            graph = globals().get('graph')\n",
    "            if graph is None:\n",
    "                graph = sg.compile()\n",
    "                globals()['graph'] = graph\n",
    "        except Exception as e:\n",
    "            with out:\n",
    "                print('Failed to compile graph:', e)\n",
    "            run_btn.disabled = False\n",
    "            fetch_levels_btn.disabled = False\n",
    "            test_btn.disabled = False\n",
    "            quick_btn.disabled = False\n",
    "            return\n",
    "\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = OutWriter(out)\n",
    "        try:\n",
    "            result = graph.invoke(state)\n",
    "            with out:\n",
    "                print('\\n--- Workflow finished ---')\n",
    "                print('Final state keys:', list(result.keys()))\n",
    "                if result.get('ics_file'):\n",
    "                    print('ICS file created:', result['ics_file'])\n",
    "                    try:\n",
    "                        display(FileLink(result['ics_file']))\n",
    "                    except Exception:\n",
    "                        print('File saved at', result['ics_file'])\n",
    "                else:\n",
    "                    print('No .ics file produced.')\n",
    "        except Exception as e:\n",
    "            with out:\n",
    "                print('\\nWorkflow failed:', e)\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            run_btn.disabled = False\n",
    "            fetch_levels_btn.disabled = False\n",
    "            test_btn.disabled = False\n",
    "            quick_btn.disabled = False\n",
    "\n",
    "    threading.Thread(target=_run, daemon=True).start()\n",
    "\n",
    "run_btn.on_click(run_clicked)\n",
    "\n",
    "# Quick flow: generate roadmap -> let user provide feedback in UI textarea -> regenerate optional -> build schedule -> export\n",
    "feedback_area = widgets.Textarea(value='', placeholder='Optional: enter brief feedback to refine roadmap', description='Feedback:', layout=widgets.Layout(width='70%', height='120px'))\n",
    "apply_feedback_btn = widgets.Button(description='Regenerate Roadmap with Feedback', button_style='')\n",
    "continue_btn = widgets.Button(description='Continue to Schedule & Export', button_style='success')\n",
    "\n",
    "# container to hold last generated state\n",
    "_quick_state = {}\n",
    "\n",
    "def quick_clicked(b):\n",
    "    quick_btn.disabled = True\n",
    "    run_btn.disabled = True\n",
    "    fetch_levels_btn.disabled = True\n",
    "    test_btn.disabled = True\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        print('Quick flow: Generating roadmap...')\n",
    "\n",
    "    def _work():\n",
    "        try:\n",
    "            state = {}\n",
    "            state['topic'] = topic_w.value\n",
    "            state['goal'] = goal_w.value\n",
    "            state['estimated_level'] = level_w.value\n",
    "            state['learning_style'] = style_w.value\n",
    "            state['available_time'] = time_w.value\n",
    "            state['target_duration_weeks'] = int(weeks_w.value) if weeks_w.value else None\n",
    "            state['export_schedule'] = bool(export_w.value)\n",
    "            # Generate roadmap (calls LLM)\n",
    "            # Capture prints from node/LLM into the output widget\n",
    "            old_stdout = sys.stdout\n",
    "            sys.stdout = OutWriter(out)\n",
    "            try:\n",
    "                roadmap_state = node_generate_roadmap(state)\n",
    "            finally:\n",
    "                sys.stdout = old_stdout\n",
    "            # Save into quick_state\n",
    "            _quick_state.clear()\n",
    "            _quick_state.update(roadmap_state)\n",
    "            with out:\n",
    "                print('\\n--- ROADMAP (preview) ---\\n')\n",
    "                print(roadmap_state.get('roadmap','(no roadmap returned)'))\n",
    "                print('\\nYou can edit feedback in the Feedback box and click \"Regenerate Roadmap with Feedback\" or click \"Continue to Schedule & Export\".')\n",
    "        except Exception as e:\n",
    "            with out:\n",
    "                print('Quick flow failed during roadmap generation:', e)\n",
    "        finally:\n",
    "            quick_btn.disabled = False\n",
    "            run_btn.disabled = False\n",
    "            fetch_levels_btn.disabled = False\n",
    "            test_btn.disabled = False\n",
    "\n",
    "    threading.Thread(target=_work, daemon=True).start()\n",
    "\n",
    "quick_btn.on_click(quick_clicked)\n",
    "\n",
    "def apply_feedback_clicked(b):\n",
    "    apply_feedback_btn.disabled = True\n",
    "    with out:\n",
    "        print('\\nRegenerating roadmap with feedback...')\n",
    "    def _work():\n",
    "        try:\n",
    "            if not _quick_state:\n",
    "                with out:\n",
    "                    print('No generated roadmap in quick session. Click Quick Roadmap first.')\n",
    "                return\n",
    "            _quick_state['feedback'] = feedback_area.value\n",
    "            # Capture prints from node/LLM into the output widget\n",
    "            old_stdout = sys.stdout\n",
    "            sys.stdout = OutWriter(out)\n",
    "            try:\n",
    "                updated = node_generate_roadmap(_quick_state)\n",
    "            finally:\n",
    "                sys.stdout = old_stdout\n",
    "            _quick_state.update(updated)\n",
    "            with out:\n",
    "                print('\\n--- UPDATED ROADMAP ---\\n')\n",
    "                print(updated.get('roadmap','(no roadmap returned)'))\n",
    "        except Exception as e:\n",
    "            with out:\n",
    "                print('Failed to regenerate roadmap with feedback:', e)\n",
    "        finally:\n",
    "            apply_feedback_btn.disabled = False\n",
    "\n",
    "    threading.Thread(target=_work, daemon=True).start()\n",
    "\n",
    "apply_feedback_btn.on_click(apply_feedback_clicked)\n",
    "\n",
    "def continue_clicked(b):\n",
    "    continue_btn.disabled = True\n",
    "    with out:\n",
    "        print('\\nBuilding schedule and exporting (if enabled)...')\n",
    "    def _work():\n",
    "        try:\n",
    "            if not _quick_state:\n",
    "                with out:\n",
    "                    print('No generated roadmap in quick session. Click Quick Roadmap first.')\n",
    "                return\n",
    "            # Build schedule\n",
    "            # Capture prints from schedule builder and export steps\n",
    "            old_stdout = sys.stdout\n",
    "            sys.stdout = OutWriter(out)\n",
    "            try:\n",
    "                schedule_state = node_schedule_builder(_quick_state)\n",
    "                _quick_state.update(schedule_state)\n",
    "                with out:\n",
    "                    print('\\n--- SCHEDULE PREVIEW ---\\n')\n",
    "                    print(_quick_state.get('schedule','(no schedule returned)'))\n",
    "                # Export if requested\n",
    "                if _quick_state.get('export_schedule', False):\n",
    "                    exported = node_export_schedule_ics(_quick_state)\n",
    "                    _quick_state.update(exported)\n",
    "                    with out:\n",
    "                        if exported.get('ics_file'):\n",
    "                            print('ICS exported to', exported['ics_file'])\n",
    "                            try:\n",
    "                                display(FileLink(exported['ics_file']))\n",
    "                            except Exception:\n",
    "                                print('File saved at', exported['ics_file'])\n",
    "                        else:\n",
    "                            print('Export step completed but no .ics file produced.')\n",
    "                else:\n",
    "                    with out:\n",
    "                        print('Export skipped (export checkbox not selected).')\n",
    "            finally:\n",
    "                sys.stdout = old_stdout\n",
    "        except Exception as e:\n",
    "            with out:\n",
    "                print('Quick continue failed:', e)\n",
    "        finally:\n",
    "            continue_btn.disabled = False\n",
    "\n",
    "    threading.Thread(target=_work, daemon=True).start()\n",
    "\n",
    "continue_btn.on_click(continue_clicked)\n",
    "\n",
    "# Quick flow UI elements grouping\n",
    "quick_box = widgets.VBox([widgets.HTML('<b>Quick Flow</b>'), feedback_area, widgets.HBox([apply_feedback_btn, continue_btn])])\n",
    "\n",
    "# Layout\n",
    "left = widgets.VBox([topic_w, goal_w, widgets.HBox([level_w, fetch_levels_btn]), style_w, time_w, weeks_w, export_w, widgets.HBox([quick_btn]) , quick_box])\n",
    "right = widgets.VBox([widgets.HBox([run_btn, test_btn]), out])\n",
    "ui = widgets.HBox([left, right], layout=widgets.Layout(align_items='flex-start'))\n",
    "\n",
    "display(HTML('<h3>Interactive LangGraph Runner</h3>'))\n",
    "display(ui)\n",
    "\n",
    "print('UI ready. Use \"Fetch Level Descriptions\" to refresh level choices from the LLM, then click \"Quick Roadmap\" or \"Run Workflow\".')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
